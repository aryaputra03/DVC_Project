name: DVC CI/CD Pipeline
on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  lint-test:
    name: Lint & test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install flake8 pytest pytest-cov
      
      - name: Lint with flake
        run: |
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=120 --statistics
      
      - name: Run test
        run: |
          pytest tests/ -v --tb=short || echo "No tests found, skipping..."

  dvc-pipeline:
    name: Run DVC Pipeline
    runs-on: ubuntu-latest  # Ganti ke ubuntu untuk kompatibilitas lebih baik
    needs: lint-test

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Penting untuk DVC

      - name: Setup python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          cache: 'pip'
      
      - name: Install DVC
        run: |
          python -m pip install --upgrade pip
          pip install "dvc[gdrive]>=3.60"  # Tambah gdrive support

      - name: Install dependencies
        run: |
          pip install -r requirements.txt  
      
      - name: Generate dataset folders
        run: |
          mkdir -p data/raw data/processed models metrics reports

      # =====================================================
      # PILIH SALAH SATU OPSI DI BAWAH INI
      # =====================================================

      # ----- OPSI A: Pull dari Google Drive Remote -----
      - name: Setup DVC Google Drive credentials
        env:
          GDRIVE_CREDENTIALS_DATA: ${{ secrets.GDRIVE_CREDENTIALS_DATA }}
        run: |
          mkdir -p ~/.config/dvc
          echo "$GDRIVE_CREDENTIALS_DATA" > ~/.config/dvc/gdrive-user-credentials.json
      
      - name: Pull data from DVC remote
        run: |
          dvc remote list
          dvc pull -v
      
      # ----- OPSI B: Download dataset dari URL (jika publik) -----
      # - name: Download dataset
      #   run: |
      #     curl -L "https://your-dataset-url.com/dataset.csv" -o data/raw/dataset.csv
      
      # ----- OPSI C: Gunakan dataset dari GitHub Releases -----
      # - name: Download from releases
      #   run: |
      #     gh release download --pattern "dataset.csv" -D data/raw/
      #   env:
      #     GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # =====================================================
      
      - name: Verify data exists
        run: |
          echo "Checking data files..."
          ls -la data/raw/
          if [ ! -f "data/raw/dataset.csv" ]; then
            echo "ERROR: dataset.csv not found!"
            exit 1
          fi
          echo "Dataset found!"

      - name: Run DVC Pipeline
        run: |
          dvc repro --force
      
      - name: Show metrics
        run: |
          echo "====== METRICS ======"
          cat metrics/metrics.json
          echo ""
          echo "===== CLASSIFICATION REPORT ====="
          cat reports/classification_report.txt

      - name: Upload Model Artifact
        uses: actions/upload-artifact@v4
        with: 
          name: trained-model 
          path: |
            models/model.pkl
            models/model_info.json
          retention-days: 30

      - name: Upload Metrics Artifact
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-metrics
          path: |
            metrics/metrics.json
            reports/classification_report.txt
          retention-days: 30
        
      - name: Upload Processed Data Artifact
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: |
            data/processed/dataset_cleaned.csv
            data/processed/test_data.csv
          retention-days: 7

      - name: Push to DVC Remote
        if: github.ref == 'refs/heads/main'
        run: dvc push